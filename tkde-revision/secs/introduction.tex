\section{introduction}
The exceptional advances of General-Purpose Graphics Processing Units (GPGPUs) 
in recent years have completely revolutionized the computing paradigm across multiple fields, including cryptocurrency mining \cite{o2014bitcoin,taylor2013bitcoin}, machine learning \cite{coates2013deep,abadi2016tensorflow}, and database technologies \cite{bakkum2010accelerating,kaldewey2012gpu}.
GPUs bring phenomenal computational power that is only available from supercomputers in the past. 
The state-of-the-art commercial GPU equipment (GV100) is capable to operate at the speed of 14.8 TFLOPS for single precision arithmetic and 870 GB/s peak memory bandwidth \footnote{Quadro GV100 launched by NVIDIA in March 2018}. 
Hence, there is a prevailing interest in developing efficient parallel algorithms on GPUs to enable real-time analytics.
%Meanwhile, as the computing resources of GPUs continue to explode, it makes rooms for more applications to run on a single GPU equipment concurrently. For example, GV100 is built with 5120 CUDA cores and 32GB device memory. Nevertheless, most GPU programs try to occupy as much resources as possible to maximize their performance individually. 
%The egoism renders inefficiency when the GPUs run multiple programs simultaneously. Imagining a number of concurrent programs requesting a total memory size larger than the device memory. Interleaving the program executions leads to redundant data transfers between CPUs and GPUs through PCIe, which is expensive in nature. 

In this paper, we investigate a fundamental data structure, i.e., \emph{hash table}, which has been implemented on GPUs to accelerate numerous applications, ranging from relational hash join \cite{he2008relational,he2009relational,heimel2013hardware}, data mining \cite{pan2011fast,zhou2010parallel,zhong2014medusa},  key value store \cite{zhang2015mega,hetherington2015memcachedgpu,breslow2016horton} and many others \cite{bowers2010parallel,pan2010efficient,garcia2011coherent,niessner2013real,wu2015gpu}. Existing works \cite{alcantara2009real,zhang2015mega,hong2010mapcg,hetherington2015memcachedgpu,breslow2016horton} focus on the static scenario: they know the data size in advance and allocate a sufficiently large hash table to insert all data entries efficiently. In many cases, the data size varies and static allocation leads to poor memory utilization~\cite{ashkiani2018dynamic}. 
The egoism renders inefficiency when an application requires multiple data structures to coexist on the GPUs. One has to resort to expensive PCIe data structure transfer between CPUs and GPUs, as the hash table takes unnecessarily large memory space. 
To fill this gap, it calls for a dynamic GPU hash table that adaptively adjusts to the size of active entries in the table. The hash table should support efficient memory management by sustaining a guaranteed \emph{filled factor} of the table when the data size changes. 
In addition to efficient memory usage, the dynamic approach should retain the performance of common hash table operations, i.e., find, delete and insert.
%Maintaining high hilled factor indicates that the table needs to be frequently adjusted to the active data size and it incurs costly rehashing to move the entries in the hash table.
%There are two major challenges for maintaining a high filled factor for hash tables on GPUs:

%\begin{itemize}
%	\item It leads to a smaller hash table size with less distinct keys, hence triggers additional conflicts as multiple threads trying to insert/delete the data, which is particularly expensive under the GPU architecture;
%	\item It also means that the table needs to be frequently adjusted to the active data size and it incurs costly rehashing to move the entries to a new table when the old table cannot accommodate the adjusted data. 
%\end{itemize}

In this paper, we propose a dynamic cuckoo hash table on GPUs, namely \voter. Cuckoo hashing \cite{pagh2004cuckoo} uses a number of hash functions to provide each key with multiple locations instead of one. When a location is occupied, existing key is relocated to make room for the new one. Existing works \cite{alcantara2009real,alcantara2011building,zhang2015mega,breslow2016horton} have demonstrated great success in speeding up their respective applications by paralleling cuckoo hash on GPUs. 
%However, most of these works require the size of a Key-Value (KV) pair to fit a single atomic transaction on GPUs (64 bits wide) to handle conflicts when multiple threads trying to update keys hashed to the same value.
%They also build on inefficient locking mechanisms to handle conflicts, which severely downgrade the performance when high contention occurs. 
However, a complete relocation of the entire hash table is required when the data cannot be  inserted.
%It thus calls for a general hash table design to support larger KV size as well as efficient relocation strategy against dynamic updates.
In this work, we offer two novel designs for implementing dynamic cuckoo hash tables on GPUs.

First, we employ the cuckoo hashing scheme with $d$ subtables specified by $d$ hash functions, and introduce a resizing policy to maintain filled factor in a bounded range, while minimizing entries in all subtables relocated at the same time. Insertions and deletions would trigger the hash tables to grow and shrink, if the filled factor falls out of the specified range. 
Our proposed policy only locks one subtable for resizing and it always ensures no subtable can be more than twice as large as any other for handling subsequent resizing efficiently. Meanwhile, the entries in the hash table are distributed so that each subtable has near-equivalent filled factor.
In this way, we drastically reduce the cost of resizing the hash tables and provide better system availability compared with existing works that need to relocate all data for resizing.
Our theoretical analysis demonstrates the optimality of the scheduling policy in terms of processing updates. 

Second, we propose a two-layer cuckoo hashing scheme to ensure efficient hash table operations. 
We note that the proposed resizing strategy requires $d$ hash tables, which indicates $d$ lookup positions for find and delete operations. Apparently, a larger $d$ indicates less workload for resizing but more lookups for find and delete operations. To mitigate the tradeoff, we devise a two-layer approach that first hashes any key to a pair of hash tables where the key can be further hashed and stored in one of the pair. 
The design ensures there are at most two lookups for any find and deletion operations, which is pivotal for GPU architecture as random lookups are particularly expensive due to small cache sizes and simplified control units.
Furthermore, the two-layer approach retains the performance guarantee of general cuckoo hash tables.
Empirically, the proposed hash table design is capable to operate efficiently at filled factors exceeding 90\%.

%Second, we propose a voter-based coordination scheme among massive GPU threads to support efficient locking without assuming the size of the key-value pairs.
%For each hash value, we allocate a bucket of $b$ locations to store key-value pairs. 
%Each thread is assigned to an insertion operation on one key. Instead of immediately acquiring a lock on the corresponding bucket to be updated, a thread will first propose a vote among its warp group and all threads in that same warp collaborate to join the winner thread for its update task. There are three distinguishing advantages for the voter-based coordination: (a) once a conflict is detected on one bucket, instead of spinning, the warp instantly revotes and switches to another bucket; (b) a near-optimal load balancing is achieved as a thread will assist other warp-aligned threads, even when the thread finishes its assigned tasks; (c) locking the bucket exclusively allows to update KV pairs without assuming their length below 64 bits.

Hereby, we summarize our contributions as follows:
\begin{itemize}
%	\item We propose a general dynamic hash table without assuming the size of the key-value pair and devise a novel voter-based coordination scheme to support the locking mechanism under massive GPU threads. 
	\item We propose an efficient strategy to resize the hash tables and our theoretical analysis has demonstrated the near-optimality of the resizing strategy.
	\item We devise a two-layer cuckoo hash scheme that ensures at most two lookups for find and deletion operations, while still retains similar performance for insertion as general cuckoo hash tables. 
	\item We conduct extensive experiments on both synthetic and real datasets and compare the proposed approach against several state-of-the-art baselines on GPU hash tables. For dynamic workloads, the proposed approach demonstrates superiority performance and reduces memory usage of up to 3x over the compared baselines.
\end{itemize}

The remaining part of this paper is organized as follows. Section~\ref{sec:pre} introduces the preliminaries and the background on GPUs, followed by the related work in Section~\ref{sec:rel}. Section~\ref{sec:dyn} introduces the hash table design and the resizing strategy against dynamic updates.
Section~\ref{sec:vot} presents two-layer cuckoo hash scheme as well as parallel operations on GPUs. The experimental results are reported in Section~\ref{sec:exp}. Finally, we conclude the paper in Section~\ref{sec:con}.